---
title: Understanding and Creating Word Embeddings
lang: en
date: 2024-12-11T00:17:50.981Z
version: 1.0.0
authors:
  - blankenship-avery
  - connell-sarah
  - dombrowski-quinn
editors:
  - ryan-yann
tags:
  - open-education
  - open-access
  - dh
  - python
  - machine-learning
categories:
  - programming-historian
featuredImage: images/understanding-creating-word-embeddings-original.png
abstract: Word embeddings allow you to analyze the usage of different terms in a
  corpus of texts by capturing information about their contextual usage. Through
  a primarily theoretical lens, this lesson will teach you how to prepare a
  corpus and train a word embedding model. You will explore how word vectors
  work, how to interpret them, and how to answer humanities research questions
  using them.
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: 2024-01-31T00:29:00.000Z
  url: https://doi.org/10.46430/phen0116
  publisher: ProgHist Ltd
licence: ccby-4.0
toc: false
draft: false
uuid: IxgyGD8XOw1090mXD9-ra
---

#### Reviewed by:    
- Anne Heyer   
- Ruben Ros   


## Learning outcomes

After completing this lesson, you will be able to:

- Know what word embedding models and word vectors are, and what kinds of questions we can answer with them
- Create and interrogate word vectors using Python
- Put together the corpus you want to analyze using word vectors
- Understand the limitations of word vectors as a methodology for answering common questions

<ExternalResource title="Interested in learning more?" subtitle="Check out this lesson on Programming Historian's website" url="https://doi.org/10.46430/phen0116" />
