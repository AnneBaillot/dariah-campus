---
title: Ethical, Societal and Legal Complexities of AI
shortTitle: Complexities of AI
lang: en
date: 2024-01-01T00:00:00.000Z
version: 1.0.0
authors:
  - genatowski-emily
tags:
  - dh
  - history-of-technology
categories:
  - dariah
featuredImage: images/ai-hero-image.jpg
abstract: This resource will cover ethical Issues including bias, privacy,
  accountability, transparency, security threats and autonomy. There will be an
  overview of the issues, examples of ethical issues pertaining to each point
  above, technical misuse that may lead to those issues and methods of
  regulation or guidance that could be implemented in order to mitigate the
  adverse ethical effects. Then it will cover Legal Issues including liability,
  intellectual property, data protection and privacy, discrimination and
  regulation. Overview of the issues, examples of each of the above, misuse that
  may lead to those issues and methods of regulation or laws that could be
  implemented in order to mitigate the legal issues stemming from the use of AI.
  Then it will cover societal Issues including employment, job displacement,
  surveillance, safety, autonomy, security and dehumanization. Overview of the
  issues, examples of issues above, systemic misuse that may lead to those
  issues and proposed regulation or guidance that could be implemented in order
  to mitigate the adverse societal effects.
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: ""
licence: ccby-4.0
toc: false
draft: false
uuid: 2nNuetnSFxZtEc4urU2XF
---
# E﻿thical, Societal and Legal Complexities of AI

Throughout this resource, the potential risks, current state and case studies of real-world examples of the complexities of AI will be detailed.  The resource is divided by ethical, societal and legal issues.

T﻿here will be examples explained for each particular complexity and then detailed case studies which will give the reader the ability to explore an external resource to learn more about the examples in each case study. 

A﻿t the end of each of the three sections, there will be a short quiz to test the knowledge acquired in each section.

![](images/ai1.jpg)

# Ethical Issues

## Potential Risks

Bias and Fairness: AI algorithms are only as good as the data they are trained on. If the training data is biased, the AI system may perpetuate or even amplify existing social inequalities. For example, biased facial recognition systems might misidentify certain racial or ethnic groups more frequently.

Privacy and Surveillance: AI systems can process vast amounts of personal data, potentially leading to privacy infringements. As AI becomes more sophisticated, there's an increased risk of surveillance, unauthorized access, and misuse of personal information.

Autonomy and Accountability: As AI systems become more advanced, they may operate autonomously, making decisions without human intervention. This raises questions about who should be held accountable for AI-generated decisions and actions when something goes wrong.

Lack of Transparency: Many AI algorithms, such as deep learning neural networks, can be complex "black boxes" that are difficult to interpret. The lack of transparency and explain-ability can make it challenging for users to understand how AI arrives at specific conclusions or recommendations.

Job Displacement and Economic Inequality: AI and automation could lead to job displacement and create economic inequality if certain sectors or regions are more affected than others. The distribution of AI's benefits and its impact on the workforce remains a concern.

Safety and Security: AI applications have the potential to be weaponized or manipulated maliciously. Ensuring that AI systems are secure and cannot be easily exploited for harmful purposes is a significant ethical challenge.

Moral Decision Making: Teaching AI systems to make moral decisions poses ethical dilemmas. Deciding what moral principles to embed in AI and how to handle situations where moral choices conflict raises complex philosophical questions.

Impact on Human Agency: AI systems that predict and influence human behavior might undermine individual autonomy and manipulate people's choices and actions without their awareness or consent.

AI in Warfare: The use of AI in military applications, such as autonomous weapons, raises ethical concerns about the potential for indiscriminate harm and the erosion of human responsibility in warfare.

Long-term Consequences and Existential Risk: Some researchers and thinkers worry about the long-term consequences of AI development, including the potential for AI systems to surpass human intelligence and the risks associated with creating superintelligent entities.

## C﻿urrent State

Bias and Fairness: The issue of bias in AI systems was a major concern. Many AI applications, including facial recognition, hiring algorithms, and credit scoring, were found to exhibit biases against certain groups, perpetuating discrimination and social inequalities.

Privacy and Surveillance: AI systems were increasingly used to process personal data, raising concerns about privacy violations and the potential for mass surveillance.

Autonomous Weapons and Military AI: The development and deployment of autonomous weapons and AI in military contexts were significant ethical issues, with concerns about the lack of human oversight and potential for increased harm.

Accountability and Transparency: The lack of transparency and explainability in AI decision-making processes remained a challenge, making it difficult to understand how AI arrived at particular outcomes and who should be held responsible for AI-generated decisions.

Job Displacement and Economic Impact: As AI and automation advanced, concerns about job displacement and economic inequality were prevalent, particularly in industries where AI technologies were replacing human labor.

Deepfakes and Misinformation: The rise of AI-generated deepfake videos and misinformation posed ethical challenges in terms of media manipulation, fake news, and potential harm to individuals and societies.

AI in Healthcare: Ethical considerations were raised regarding the use of AI in healthcare for tasks such as diagnosis and treatment recommendations, with concerns about data privacy, informed consent, and potential biases in medical decision-making.

Manipulation and Persuasion: The use of AI-driven algorithms in social media platforms and advertising raised concerns about targeted manipulation and persuasion, potentially influencing people's beliefs and behaviors.

Data Governance and Ownership: The increasing reliance on data for training AI models brought up questions about data ownership, access, and governance, particularly in cases involving sensitive or personal data.

Ethical AI Research and Development: Ethical considerations within the AI research and development community became more prominent, with efforts to promote responsible AI practices and the integration of ethics into AI development processes.

<Quiz>
  <Quiz.Card>
    <Quiz.MultipleChoice>
      <Quiz.Question>
        W﻿here does the bias in AI derive from?
      </Quiz.Question>

      <Quiz.MultipleChoice.Option>
        T﻿he User
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option isCorrect>
        T﻿he Training Data
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option>
        T﻿he Algorithm
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option>
        T﻿he Coder
      </Quiz.MultipleChoice.Option>
    </Quiz.MultipleChoice>
  </Quiz.Card>
</Quiz>


## C﻿ase Studies

Autonomous Vehicles and Pedestrian Safety: In March 2018, a self-driving Uber vehicle struck and killed a pedestrian in Tempe, Arizona. The incident raised concerns about the safety of autonomous vehicles and the need for human oversight during testing and deployment.



<ExternalResource title="Interested in learning more?" subtitle="Check out New York Times coverage of Uber's Self Driving Car Safety Incident" url="https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html" />



Facial Recognition Bias: In 2018, Joy Buolamwini, an MIT researcher, found that some facial recognition systems from major tech companies were less accurate in identifying darker-skinned and female faces compared to lighter-skinned and male faces. 

<ExternalResource title="Interested in learning more?" subtitle="Visit Gender Shades website to read more about the inequality in facial recognition" url="http://gendershades.org" />



Automated Hiring Bias: In 2018, it was reported that Amazon developed an AI-powered recruiting tool that showed bias against female candidates, downgrading resumes that included terms like "women's" and penalizing applicants from women's colleges.

<ExternalResource title="Interested in learning more?" subtitle="Read about the automated hiring bias AI that was scrapped by Amazon on Reuters" url="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" />



AI in Criminal Justice: In 2016, ProPublica investigated the use of the COMPAS algorithm in the U.S. criminal justice system. The algorithm, used to assess the likelihood of a defendant reoffending, was found to have significant racial bias, leading to biased decisions in sentencing. 

<ExternalResource title="Interested in learning more?" subtitle="Explore ProPublica's investigation of AI in the US criminal justice system" url="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" />

AI in Healthcare: In 2017, Google's DeepMind was involved in a controversy when it partnered with the UK's National Health Service (NHS) to process patient data without explicit consent. The partnership raised concerns about data privacy and informed consent. 

<ExternalResource title="Interested in learning more?" subtitle="Read the Guardian's coverage of Google's DeepMind AI and the UK's NHS" url="https://www.theguardian.com/technology/2017/jul/03/google-deepmind-16m-patient-royal-free-deal-data-protection-act" />



![](images/ai3.jpg)

# Societal Issues

## P﻿otential Risks

Job Displacement and Economic Inequality: AI and automation could lead to job displacement across various industries, potentially exacerbating economic inequality as certain sectors are more affected than others. Ensuring a just transition for workers and addressing the impact on income distribution is critical.

Skills Gap and the Digital Divide: The adoption of AI may create a skills gap, where the demand for AI-related expertise outstrips the supply. Unequal access to AI technologies could widen the digital divide between regions or socio-economic groups, further marginalizing disadvantaged communities.

Ethical Decision Making and Agency: As AI systems take on more decision-making roles, questions arise about how to imbue AI with ethical principles and ensure that AI respects human agency and values. AI algorithms can perpetuate and amplify existing biases, leading to discriminatory outcomes in areas like criminal justice, hiring, and lending.

Surveillance and Privacy Concerns: The extensive use of AI for surveillance purposes, both by governments and private entities, may raise serious privacy concerns and potential abuse of personal data.

Autonomous Weapons and Warfare: The development of AI-driven autonomous weapons could raise ethical concerns about the potential for uncontrolled use and accountability in warfare.

AI and Addiction: AI-driven algorithms in entertainment and social media platforms may contribute to addiction-like behaviors and excessive screen time, particularly among vulnerable populations.

Unemployment and Social Safety Nets: Widespread job displacement due to AI adoption may necessitate the restructuring of social safety nets to support those affected.

Human-Machine Interaction and Social Isolation: As AI becomes more integrated into daily life, establishing appropriate and ethical human-machine interaction norms and guidelines becomes crucial. Increasing reliance on AI and automation may lead to reduced human interactions and social isolation, potentially impacting mental health and well-being.

Existential Risk: Some researchers and thinkers express concern about the potential for AI to surpass human intelligence, leading to existential risks that may require careful management and oversight.

Deepfakes and Misinformation: The rise of AI-generated deepfake videos and misinformation can have significant societal consequences, leading to confusion, distrust, and the erosion of truth.

## C﻿urrent State

Ethics of AI Development and Use: The ethical considerations surrounding AI research, development, and deployment were widely discussed, including issues related to transparency, accountability, and the ethical implications of AI-driven decisions.

AI and Politics: Concerns about the influence of AI-driven misinformation on political discourse and election processes were prominent.

AI and Education: The role of AI in education and the potential impact on the workforce and learning outcomes were subjects of debate.

AI and Climate Change: The potential for AI to contribute positively to addressing climate change and sustainability was being explored, along with concerns about its environmental impact.

Data Privacy and Security: The use of AI involved significant data collection and processing, raising concerns about data privacy, cyber security, and potential misuse of personal information.

AI Bias and Discrimination: Concerns about bias in AI systems, leading to discriminatory outcomes in areas such as hiring, lending, and criminal justice, were already prominent.

Job Displacement and Economic Impact: The potential for AI and automation to displace jobs and impact certain industries was a significant societal concern. Discussions about re-skilling and workforce transition were ongoing.

AI and Surveillance: The increasing use of AI for surveillance purposes, both by governments and private entities, raised ethical and privacy concerns.

AI Content Moderation and Misinformation: The use of AI for content moderation on social media platforms and its role in combating misinformation and hate speech raised challenges related to freedom of expression and algorithmic biases.

AI in Criminal Justice: Discussions about the use of AI algorithms in predictive policing and sentencing, and the potential for bias and fairness issues, were ongoing.

<Quiz>
  <Quiz.Card>
    <Quiz.MultipleChoice>
      <Quiz.Question>
        W﻿hy does AI taking over jobs present such a societal issue?
      </Quiz.Question>

      <Quiz.MultipleChoice.Option>
        Creative jobs being taken over will lead to a lack of artistry
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option isCorrect>
        A﻿I may progress with uneven job displacement furthering inequality
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option>
        T﻿hose who lose jobs to AI may not be able to be retrained
      </Quiz.MultipleChoice.Option>
    </Quiz.MultipleChoice>
  </Quiz.Card>
</Quiz>


## C﻿ase Studies

AI and Surveillance: China's use of AI-driven surveillance and its social credit system, which scores citizens based on their behavior, raised significant ethical and privacy concerns.

<ExternalResource title="Interested in learning more?" subtitle="Read up on The Diplomat's coverage of China's Social Credit System " url="https://thediplomat.com/2019/11/the-real-dangers-of-chinas-social-credit-system/" />



AI and Consumer Manipulation: Exploring the ethical implications of AI-powered behavioral advertising and its potential to manipulate consumer behavior and choices.

<ExternalResource title="Interested in learning more?" subtitle="Explore Wired's deep dive into behavioral advertising" url="https://www.wired.co.uk/article/behavioural-advertising" />

AI and Social Media: Examining how AI algorithms can amplify online harassment and hate speech, leading to toxic online environments.

<ExternalResource title="Interested in learning more?" subtitle="Investigate The Guardian's exploration of AI and Social Media Misogyny " url="https://www.theguardian.com/technology/2020/oct/12/dark-side-of-social-media-misogyny-women-online-abuse" />



AI and Disinformation: Research on how AI can be used to create and propagate disinformation, leading to misinformation campaigns and their potential impact on society.

<ExternalResource title="Interested in learning more?" subtitle="Read up on research by Georgetown researchers on the malicious use of AI" url="https://cset.georgetown.edu/research/the-malicious-use-of-artificial-intelligence/" />

AI and Job Displacement: Examining the potential impact of AI and automation on low-wage workers and vulnerable populations, and the need for policies to address economic inequality.

<ExternalResource title="Interested in learning more?" subtitle="Explore Brookings' research on Job Displacement from Automation and AI " url="https://www.brookings.edu/research/automation-and-artificial-intelligence-how-machines-affect-people-and-places/" />

![](images/ai2.jpg)

# Legal Issues

## Potential Risks

Liability and Accountability: Determining liability when AI systems cause harm or make erroneous decisions without human intervention is a complex legal issue. Questions arise about who is responsible - the AI developer, the user, or the AI system itself.

Data Privacy and Ownership: The extensive use of AI relies on vast amounts of data. Legal issues related to data privacy, consent, and ownership might become more complex as AI systems collect and process personal information.

Intellectual Property: Legal challenges could emerge concerning AI-generated works and inventions. Determining the ownership and copyright of AI-generated content or patents could be contentious.

Regulation of AI Technology: Developing a regulatory framework for AI poses significant challenges. Striking a balance between fostering innovation and ensuring safety and ethical use is a complex legal endeavor.

AI in Healthcare and Medicine: The use of AI in medical diagnosis and treatment may lead to questions about medical malpractice, privacy, and the appropriate level of human oversight.

AI in Criminal Justice: AI systems might be used in predictive policing or risk assessment. Legal challenges could arise regarding the fairness, transparency, and potential bias of such systems.

Security and Hacking: The use of AI in cyber-security may lead to legal issues concerning the accountability of AI-powered security measures and potential misuse of AI for hacking and cyber-attacks.

Autonomous Weapons and Warfare: Concerns about AI-driven weapons and their regulation could lead to international legal debates regarding the use of lethal autonomous systems in warfare.

Consumer Protection: Legal issues may arise related to the transparency and disclosure of AI systems in consumer products and services, particularly concerning potential biases or misleading functionalities.

Robot Rights: As AI and robotics become more advanced, there could be discussions about the legal status of AI entities, their rights, and their responsibilities.

## C﻿urrent State

Data Privacy and Security: Data privacy laws, such as the European Union's General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), were already in effect to regulate the collection, storage, and processing of personal data by AI systems.

Algorithmic Bias and Discrimination: The potential for AI algorithms to exhibit bias and discriminate against certain groups was a significant concern. Some jurisdictions explored ways to address algorithmic bias and ensure fairness in AI decision-making.

Intellectual Property and Copyright: Questions about copyright and intellectual property rights arose as AI-generated content, such as art, music, and writing, became more prevalent. Determining the ownership and protection of AI-generated works was a complex legal issue.

Liability and Responsibility: The allocation of liability and responsibility for AI actions and decisions was a challenging legal question, particularly in cases where AI systems operated autonomously without direct human oversight.

Regulatory Frameworks: Countries and regions were in the process of developing regulatory frameworks to address the unique challenges posed by AI. Some focused on safety regulations for AI in specific domains, such as autonomous vehicles.

Autonomous Vehicles: Legal issues concerning the deployment of autonomous vehicles were under scrutiny, including liability in accidents and the responsibilities of manufacturers and developers.

AI in Healthcare and Medicine: Legal considerations in the use of AI for medical diagnosis, treatment recommendations, and patient care included issues related to liability, informed consent, and medical malpractice.

Intellectual Property Infringement: Legal disputes arose over the use of AI technology for intellectual property infringement, such as using AI to create counterfeit products or infringing copyrighted content.

AI in Criminal Justice: The use of AI in predictive policing and risk assessment faced legal challenges related to transparency, fairness, and potential bias.

Autonomous Weapons: Discussions about the legal regulation and potential ban of lethal autonomous weapons were ongoing in international forums and organizations.

<Quiz>
  <Quiz.Card>
    <Quiz.MultipleChoice>
      <Quiz.Question>
        W﻿hen an AI makes a decision which leads to injury or death, who is legally liable?
      </Quiz.Question>

      <Quiz.MultipleChoice.Option>
        T﻿he Developer
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option>
        T﻿he User
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option>
        T﻿he AI Itself
      </Quiz.MultipleChoice.Option>

      <Quiz.MultipleChoice.Option isCorrect>
        W﻿e have yet to determine a standard of legal liability
      </Quiz.MultipleChoice.Option>
    </Quiz.MultipleChoice>
  </Quiz.Card>
</Quiz>


## C﻿ase Studies

Facial Recognition and Privacy: In 2020, Clearview AI, a facial recognition company, faced multiple lawsuits and legal challenges over privacy concerns. The company scraped billions of images from social media platforms without users' consent, raising questions about data privacy and the use of facial recognition technology.

<ExternalResource title="Interested in learning more?" subtitle="Read the New York Time's coverage of Clearview AI's Privacy Concerns" url="https://www.nytimes.com/2020/05/29/technology/clearview-ai-lawsuit-privacy.html" />

AI and Copyright Infringement: In a long-standing legal battle, Google and Oracle clashed over the use of Java APIs in Android's operating system. The case raised important questions about the fair use of APIs and the intersection of copyright law and AI-driven software development.

<ExternalResource title="Interested in learning more?" subtitle="Find out more about the Supreme Court's opinions on AI and Copyright Infringement" url="https://www.supremecourt.gov/opinions/20pdf/18-956_d18f.pdf" />

AI and Election Interference: The Cambridge Analytica scandal in 2018 revealed how AI-driven data analytics were used to collect and manipulate user data for targeted political advertising, raising concerns about election interference and data privacy.

<ExternalResource title="Interested in learning more?" subtitle="Deep Dive into Cambridge Analytica's 2018 Scandal through The Guardian's Coverage" url="https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election" />

AI and Intellectual Property: In 2020, IBM filed a lawsuit against Airbnb, accusing the company of infringing on IBM's patents with its AI-powered technologies. The case highlighted the legal complexities in AI patent disputes.

<ExternalResource title="Interested in learning more?" subtitle="Read Bloomberg's coverage of the IBM IP Lawsuit against Airbnb" url="https://news.bloomberglaw.com/ip-law/ibm-sues-airbnb-alleging-patent-infringement-over-tech-tools" />

AI in Education: Proctorio, an AI-powered remote proctoring service, faced legal challenges related to data privacy and surveillance concerns. The software was used to monitor students during online exams, raising questions about privacy and data security. 

<ExternalResource title="Interested in learning more?" subtitle="Read Vice's coverage of Universities use of AI Proctoring Software" url="https://www.vice.com/en/article/4ad3a8/universities-are-finally-pressuring-proctorio-to-stop-spying-on-students" />