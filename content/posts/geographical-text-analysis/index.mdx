---
title: Geographical Text Analysis
lang: en
date: 2022-01-31T00:00:00.000Z
version: 1.0.0
authors:
  - bellamy-katherine
  - hacıgüzeller-piraye
  - kahn-rebecca
  - murrieta-flores-patricia
tags:
  - spatial-humanities
  - data-visualisation
  - dh
  - geotagging
abstract: "Geographical Text Analysis (GTA) is a relatively recent development
  in the approach to studying, analysing, and extracting the content of textual
  sources. Combining techniques from Natural Language Processing (NLP), Corpus
  Linguistics, and Geographic Information Systems (GIS), GTA offers a new
  methodology for employing these computational tools in Humanities research.
  The development of this methodology by researchers at Lancaster
  University  builds upon the ‘distant reading’ approach coined by Franco
  Moretti in the field of Literature.  With a focused interest in querying the
  geographic nature of textual sources, GTA focuses on the identification,
  manipulation, and analysis of spatial information on a large scale. "
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: ""
licence: ccby-4.0
toc: false
draft: false
uuid: n6QGzjFXm03e0vWt9xDup
categories:
  - dariah
---
Geographical Text Analysis (GTA) is a relatively recent development in the approach to studying, analysing, and extracting the content of textual sources. Combining techniques from Natural Language Processing (NLP), Corpus Linguistics, and Geographic Information Systems (GIS), GTA offers a new methodology for employing these computational tools in Humanities research. The development of this methodology by researchers at Lancaster University builds upon the ‘distant reading’ approach coined by Franco Moretti in the field of Literature. With a focused interest in querying the geographic nature of textual sources, GTA focuses on the identification, manipulation, and analysis of spatial information on a large scale.

**The following points briefly summarise how this process works:**

1) Use of NLP techniques to automatically identify proper nouns (this may be augmented/refined through the use of ontologies designed specifically for a certain corpus/subject interest).

2) Assigning coordinates automatically to place-names in the corpus by matching these to place-names in a geographical dictionary or gazetteer, a technique called geoparsing.

3) Implementation of Corpus Linguistics techniques to reveal significant linguistic regularities or patterns. This is particularly important for verifying key concepts as they relate to individual places.

4) The mapping of identified data and, subsequently, the spatial analysis of this data using GIS software.

Each of these individual steps requires expertise in distinct fields. By bringing these techniques together, we have the opportunity to ask new, complex questions and reveal new insights into large corpora that would otherwise require years of close-reading. Of course, it is vital to recognise that the use of computational approaches in these circumstances is a complementary endeavour, and should not be viewed as a replacement to close-reading.

The following two case studies provide a brief insight into the application of these techniques practice:

## MAPPING THE LAKES: A Literary GIS
This pilot project at Lancaster University explored the use of GIS technology in furthering our understanding of the literature of space and place. Mapping out two historical textual accounts of journeys through the landscape of the Lake District in the UK, this project explored the processes, tools, and possibilities of Geographical Text Analysis.
Read more about the project: https://www.lancaster.ac.uk/mappingthelakes/

## DIGGING INTO EARLY COLONIAL MEXICO: A large-scale computational analysis of 16th century historical sources
This collaborative, interdisciplinary project brings together experts from three countries and institutions in the fields of History, Archaeology, Geography, and Computer Science. Their work combines techniques from Corpus Linguistics, Text Mining, NLP, Machine Learning, and GIS in order to analyse the Relaciones Geográficas, a large corpus of geographic reports produced in sixteenth-century New Spain. In doing so, its key objective is to advance and develop new computational approaches for the investigation and analysis of historical sources in particular. 
Read more about the project: https://www.lancaster.ac.uk/digging-ecm/

### FUTURE DEVELOPMENTS
A dedicated Geographical Text Analysis tool is currently in development as part of the aforementioned Digging Into Early Colonial Mexico project. The GTA tool – available later in 2021 – will streamline the process of identifying, georeferencing, processing, and mapping geographical information contained within textual sources in a non-specialist, user-friendly way. Users will be able to upload their own text, with each of the previously mentioned steps being computed automatically in the background, producing a dataset that can be both visualised within the tool and downloaded for further external analysis.
To keep up to date with progress of the GTA tool, follow the project on Twitter: [@DiggingCH](https://twitter.com/DiggingCH). 
 
