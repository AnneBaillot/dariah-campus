---
title: Geographical Text Analysis
lang: en
date: 2022-01-31T00:00:00.000Z
version: 1.0.0
authors:
  - bellamy-katherine
  - hacıgüzeller-piraye
  - kahn-rebecca
  - murrieta-flores-patricia
tags:
  - spatial-humanities
  - data-visualisation
  - dh
  - geotagging
abstract: "Geographical Text Analysis (GTA) is a relatively recent development
  in the approach to studying, analysing, and extracting the content of textual
  sources. Combining techniques from Natural Language Processing (NLP), Corpus
  Linguistics, and Geographic Information Systems (GIS), GTA offers a new
  methodology for employing these computational tools in Humanities research.
  The development of this methodology by researchers at Lancaster
  University  builds upon the ‘distant reading’ approach coined by Franco
  Moretti in the field of Literature.  With a focused interest in querying the
  geographic nature of textual sources, GTA focuses on the identification,
  manipulation, and analysis of spatial information on a large scale. "
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: ""
licence: ccby-4.0
toc: false
draft: false
uuid: n6QGzjFXm03e0vWt9xDup
categories:
  - dariah
---
Geographical Text Analysis (GTA) is a relatively recent development in the approach to studying, analysing, and extracting the content of textual sources. Combining techniques from Natural Language Processing (NLP), Corpus Linguistics, and Geographic Information Systems (GIS), GTA offers a new methodology for employing these computational tools in Humanities research. The development of this methodology by researchers at Lancaster University builds upon the ‘distant reading’ approach coined by Franco Moretti in the field of Literature. With a focused interest in querying the geographic nature of textual sources, GTA focuses on the identification, manipulation, and analysis of spatial information on a large scale.

**The following points briefly summarise how this process works:**

1) Use of NLP techniques to automatically identify proper nouns (this may be augmented/refined through the use of ontologies designed specifically for a certain corpus/subject interest).

2) Assigning coordinates automatically to place-names in the corpus by matching these to place-names in a geographical dictionary or gazetteer, a technique called geoparsing.

3) Implementation of Corpus Linguistics techniques to reveal significant linguistic regularities or patterns. This is particularly important for verifying key concepts as they relate to individual places.

4) The mapping of identified data and, subsequently, the spatial analysis of this data using GIS software.

Each of these individual steps requires expertise in distinct fields. By bringing these techniques together, we have the opportunity to ask new, complex questions and reveal new insights into large corpora that would otherwise require years of close-reading. Of course, it is vital to recognise that the use of computational approaches in these circumstances is a complementary endeavour, and should not be viewed as a replacement to close-reading.

The following two case studies provide a brief insight into the application of these techniques practice: