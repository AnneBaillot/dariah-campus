---
title: Geographical Text Analysis
lang: en
date: 2022-01-31T00:00:00.000Z
version: 1.0.0
authors:
  - bellamy-katherine
  - hacıgüzeller-piraye
  - kahn-rebecca
  - murrieta-flores-patricia
tags:
  - spatial-humanities
  - data-visualisation
  - dh
  - geotagging
abstract: "Geographical Text Analysis (GTA) is a relatively recent development
  in the approach to studying, analysing, and extracting the content of textual
  sources. Combining techniques from Natural Language Processing (NLP), Corpus
  Linguistics, and Geographic Information Systems (GIS), GTA offers a new
  methodology for employing these computational tools in Humanities research.
  The development of this methodology by researchers at Lancaster
  University  builds upon the ‘distant reading’ approach coined by Franco
  Moretti in the field of Literature.  With a focused interest in querying the
  geographic nature of textual sources, GTA focuses on the identification,
  manipulation, and analysis of spatial information on a large scale. "
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: ""
licence: ccby-4.0
toc: false
draft: false
uuid: n6QGzjFXm03e0vWt9xDup
categories:
  - dariah
---
Geographical Text Analysis (GTA) is a relatively recent development in the approach to studying, analysing, and extracting the content of textual sources. Combining techniques from Natural Language Processing (NLP), Corpus Linguistics, and Geographic Information Systems (GIS), GTA offers a new methodology for employing these computational tools in Humanities research. The development of this methodology by researchers at Lancaster University builds upon the ‘distant reading’ approach coined by Franco Moretti in the field of Literature. With a focused interest in querying the geographic nature of textual sources, GTA focuses on the identification, manipulation, and analysis of spatial information on a large scale.

**The following points briefly summarise how this process works:**

1. Use of NLP techniques to automatically identify proper nouns (this may be augmented/refined through the use of ontologies designed specifically for a certain corpus/subject interest).
2. Assigning coordinates automatically to place-names in the corpus by matching these to place-names in a geographical dictionary or gazetteer, a technique called geoparsing.
3. Implementation of Corpus Linguistics techniques to reveal significant linguistic regularities or patterns. This is particularly important for verifying key concepts as they relate to individual places.
4. The mapping of identified data and, subsequently, the spatial analysis of this data using GIS software.

Each of these individual steps requires expertise in distinct fields. By bringing these techniques together, we have the opportunity to ask new, complex questions and reveal new insights into large corpora that would otherwise require years of close-reading. Of course, it is vital to recognise that the use of computational approaches in these circumstances is a complementary endeavour, and should not be viewed as a replacement to close-reading.

The following two case studies provide a brief insight into the application of these techniques practice:

## MAPPING THE LAKES: A Literary GIS

This pilot project at Lancaster University explored the use of GIS technology in furthering our understanding of the literature of space and place. Mapping out two historical textual accounts of journeys through the landscape of the Lake District in the UK, this project explored the processes, tools, and possibilities of Geographical Text Analysis.
Read more about the project: https://www.lancaster.ac.uk/mappingthelakes/

## DIGGING INTO EARLY COLONIAL MEXICO: A large-scale computational analysis of 16th century historical sources

This collaborative, interdisciplinary project brings together experts from three countries and institutions in the fields of History, Archaeology, Geography, and Computer Science. Their work combines techniques from Corpus Linguistics, Text Mining, NLP, Machine Learning, and GIS in order to analyse the Relaciones Geográficas, a large corpus of geographic reports produced in sixteenth-century New Spain. In doing so, its key objective is to advance and develop new computational approaches for the investigation and analysis of historical sources in particular. 
Read more about the project: https://www.lancaster.ac.uk/digging-ecm/

### FUTURE DEVELOPMENTS

A dedicated Geographical Text Analysis tool is currently in development as part of the aforementioned Digging Into Early Colonial Mexico project. The GTA tool – available later in 2021 – will streamline the process of identifying, georeferencing, processing, and mapping geographical information contained within textual sources in a non-specialist, user-friendly way. Users will be able to upload their own text, with each of the previously mentioned steps being computed automatically in the background, producing a dataset that can be both visualised within the tool and downloaded for further external analysis.
To keep up to date with progress of the GTA tool, follow the project on Twitter: [@DiggingCH](https://twitter.com/DiggingCH). 

### TUTORIAL BACKGROUND

Place names are the most widely used way of expressing a location. They occur in a wide range of different types of sources, from quantitative sources such as census data, where each row of data is referred to by place name, to unstructured texts such as a description of a journey or an official report. As such, place names are extremely important to humanities geographies. One of the major challenges in building a GIS database is often to convert place names into the precisely defined, coordinate-based locations required by spatial data in GIS.

Sometimes, place names refer to a specific and precisely defined administrative unit such as a municipality, district or county in census data. In these cases, polygons are usually the most suitable way of representing the places that the names refer to. More often, however, the location a place name refers to is vaguer. In phrases such as “Scarlet fever was prevalent in Manchester and Salford” or “Helm Crag is a high mountain near Grasmere” (place names are shown in italics) the places that the text is referring to are not precisely delimited, indeed, Grasmere can refer to either the lake or the village next to it. In these cases, a point is usually a much more satisfactory and convenient way of representing the location. The challenge, however, is to find coordinates for the place names.

Gazetteers can be particularly useful, if not crucial, for performing this task. A gazetteer can be thought of as a sort of ‘geographical directory’ that provides basic reference information about the geographical makeup of a country, a region, or even a continent. From a GIS perspective, a gazetteer must contain a minimum of place names and coordinates for those places. It may also contain additional information such as population size, areas, heights, feature types (town, mountain, river, etc.), and so on. Gazetteers are becoming increasingly available for free. In this exercise we will look at the GeoNames gazetteer (www.GeoNames.org) in particular, however, many other gazetteers are also available. We will also encounter GeoNames and some other gazetteers when we annotate place-names in a text within Recogito, an online annotation tool.

Google Maps, Google Earth and other online mapping tools also have large gazetteers behind them as part of their search facilities. These are not available to download but can be used to locate places individually if they are not in one of the publicly available gazetteers. 

### DATA SOURCES

The aim of this exercise is to georeference two sources. The first is a table derived from Samuel Taylor Coleridge’s 1802 Tour of the Lake District and already has coordinates. The second is an excerpt from William Wordsworth’s 1835 Guide through the District of the Lakes in the North of England, from which we will need to extract place-names and assign coordinates. To do this, we will use Recogito (an online annotation tool) and then find and correct any places that fail to be identified using Recogito. 
Before getting started, make sure you download the DARIAH-GTA.zip file, then right click on it to ‘Extract all’ (or ‘unzip’ the file) somewhere on your computer, so that we can use the data within (all the shapefiles we need are in their own QGIS-Shapefiles.zip folder contained within DARIAH-GTA.zip – do not unzip QGIS-Shapefiles.zip) The following table provides a summary of all files contained within the DARIAH-GTA.zip file:

| File Name            | Description                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| -------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| GB.tx                | The UK data from Geonames.                                                                                                                                                                                                                                                                                                                                                                                                                         |
| readme.txt           | The readme file that accompanies GB.txt                                                                                                                                                                                                                                                                                                                                                                                                            |
| admin1CodesASCII.txt | GeoNames look-up table that provides metadata for the admin1_code field.                                                                                                                                                                                                                                                                                                                                                                           |
| Cole_other.csv       | A Comma Separated Values file giving the places that Coleridge mentions in his 1802 tour. **Pl_name** the place name as it appears in his text.**Visited** whether he visited it (Y), talks about it from a distance (N), or if this is unclear (U). **Date** and **cal_date** the date in two different formats. **St_name** a standardised version of the name as taken from a gazetteer. **Latitude** and **Longitude** taken from a gazetteer. |
| Wordsworth_Guide.txt | A text file that contains an excerpt from Wordsworth’s Guide, specifically the first chapter: ‘Directions and Information For The Tourist’, with references to many of the places discussed in the Guide. We will upload this text into Recogito for annotation. For the full text of Wordsworth’s Guide, click [here](https://romantic-circles.org/editions/guide_lakes/editions.2020.guide_lakes.1835.html).                                     |
| Lakes_towns          | A shapefile containing the names and locations of the major towns in and around the Lake District. **Town_name** is the name of the town, **Resident** names any famous writers that lived there. The source of this shapefile, its selection criteria and accuracy are not given.                                                                                                                                                                 |
| Main_Roads           | A line shapefile that shows the major turnpike roads of the period. **Route** gives the start and end points of each segment (‘Br.’ stands for ‘Bridge’). Again, the source, accuracy and selection criteria are not specified.                                                                                                                                                                                                                    |
| Lake_Cnty            | A polygon shapefile containing the three counties that made up the Lake District until reorganisation in the 1970s. **County** gives the county name.                                                                                                                                                                                                                                                                                              |
| Lakes                | A polygon shapefile containing the major Lakes in the Lake District. **Name** gives the name of the Lake.                                                                                                                                                                                                                                                                                                                                          |
| Coast                | A polygon shapefile containing part of the UK coastline, for reference.                                                                                                                                                                                                                                                                                                                                                                            |

### THE GeoNames GAZETTEER

GeoNames is on online, freely available gazetteer, with which it is possible to view and download a variety of basic information about places (see www.GeoNames.org). GeoNames draws its information from a wide range of sources, the full list of which can be viewed by clicking here. In addition, GeoNames is an ‘open’ development, meaning that users may edit, correct and add new information to the existing database. At the time of writing this practical, the GeoNames database contains over 25 million geographical names, from all around the Earth. Geographical coordinates for locations are given in latitude/longitude measurements in the WGS84 (World Geodetic System 1984) geographic coordinate system.

The main user interface to GeoNames consists of a simple menu, as shown below:

![](images/picture-1.jpg)

This interface is intended to aid users who wish only to look up information on a particular place; however, it is also possible to download all of the data for a particular country. In this practical, you will use the GeoNames ‘country file’ containing entries for the UK, **GB.txt**. This has already been downloaded to the DARIAH-GTA.zip file for you. Other country’s data is available by following the link to _Free Gazetteer Data_ under _Download_.

### SUMMARIZED GUIDELINES FOR COMPLETING TUTORIAL

First, we will load the **Cole_other.csv** file into QGIS – this file already contains coordinates, so it is a straight-forward process to visualise this data in QGIS.

Next, we will take the **Wordsworth_Guide.txt** text excerpt and use a series of techniques to assign coordinates to the places referenced in the text. To do this, we will: 

- Load **Wordsworth_Guide.txt** into Recogito.
- Use Recogito to annotate and assign coordinates to key place-names.
- Export our data from Recogito.
- Use other sources to locate coordinates for places unidentified within Recogito
- Convert our textual data into a GeoPackage.
- Edit and clean data within QGIS.
- Explore the GeoNames data and join it with our data. 

### STEP-BY-STEP INSTRUCTIONS

**1.	Georeferencing a table that contains coordinates**

The file **Cole_other.csv** is a Comma Separated Values file that contains places mentioned in Coleridge’s text together with some other information and, crucially, the latitude and longitude that the place names refer to. (It doesn’t matter whether these files are database tables, or text files such as csv or tab delimited, when you have information that has coordinates, loading it into QGIS, georeferencing it and saving it as a GeoPackage is easy.)

**a.	Check the file in Excel**

- Open Excel.
- Go to _File_ > _Open_, and then select _Browse_.

![](images/picture-2.jpg)

- When the dialog box appears, navigate to location where you saved the DARIAH-GTA folder earlier, and make sure to change the menu in the bottom right corner from _All Excel Files_ to _Text Files_ (see above).
- Click on **Cole_other.csv**.
- Press _Open_.
- Because this is a .csv file, a ‘Text Import Wizard’ will appear to guide you through opening this data in Excel. On Step 1, make sure that **Delimited** is selected under the ‘Original data type’, and that the ‘My data has headers’ box is ticked. 

![](images/picture-3.jpg)

- Click _Next_ to proceed to Step 2, where you need to select your ‘Delimiters’: make sure **Comma** is selected. You can then click _Finish_ (leaving the defaults selected for Step 3).
- You should now see the contents of **Cole.csv** loaded in Excel. You will notice that the file contains two versions of place name. The first, **pl_name**, is the spelling from the text, the second, **st_name**, (meaning standardised name) is the spelling that appears in the gazetteer that was used to georeferenced this. The file also contains latitude and longitude, and a range of other data.
- When you are happy, close the file (you don’t need to save the file as we haven’t made any changes).

**b.	Opening files in QGIS**

- Open a new QGIS project and save it as GTA_Lakes.

  - **NOTE**: Make sure to keep saving your QGIS project regularly throughout the tutorial!
- All of the shapefiles we need are located in their own folder within the DARIAH-GTA folder we saved earlier. To open them, select the _Layer_ drop-down menu within QGIS, then _Add layer_ > _Add Vector Layer_

![](images/picture-4.jpg)

- This opens the ‘Data Source Manager’ – click the three small dots next to ‘Vector Dataset’ and navigate to the DARIAH-GTA folder you downloaded earlier, locate the **QGIS-Shapefiles.zip** file within the folder and click to _Open_ this file.

![](images/picture-5.jpg)

- Click _Add_ within the Data Source Manager. QGIS will then ask you which Layers you would like to add. **Select all** those that appear within the ‘QGIS-Shapefiles’ folder, as follows: (**Coast.shp**; **Lake_Cnty.shp**; **Lakes.shp**; **Lakes_towns.shp**; **Main_Roads.shp**) 

![](images/picture-6.jpg)

- Click **OK**, and then close the Data Source Manager. All 5 of these layers should appear in your list of Layers at the bottom-left of your screen. You can close the Data Source Manager, and you should see something similar to the below:
- **NOTE**: If you wish, you can alter the appearance of your layers by double-clicking on the symbol in the ‘Layers’ list, or right-clicking on your layer, then selecting ‘Properties’.

![](images/picture-7.jpg)

**c. Creating a georeferenced file**

- We can now start loading our other data. Once again, select Layer > Add Layer from the drop-down menu. This time, though, we will use Add delimited text layer.
