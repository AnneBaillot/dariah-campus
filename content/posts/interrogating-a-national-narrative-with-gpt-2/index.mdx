---
title: Interrogating a National Narrative with GPT-2
lang: en
date: 2022-10-03T00:00:00.000Z
version: 1.0.0
authors:
  - brousseau-chantal
editors:
  - ladd-john-r
  - garcia-tiago-sousa
contributors:
  - mcdonough-katherine
  - viola-lorella
tags:
  - dh
  - open-education
  - open-access
  - python
  - machine-learning
categories:
  - programming-historian
featuredImage: https://programminghistorian.org/gallery/interrogating-national-narrative-gpt.png
abstract: In this lesson, you will learn how to apply a Generative Pre-trained
  Transformer language model to a large-scale corpus so that you can locate
  broad themes and trends within written text.
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: 2022-10-03T00:00:00.000Z
  url: https://doi.org/10.46430/phen0104
  publisher: ProgHist Ltd
licence: ccby-4.0
toc: false
draft: false
uuid: hrF50bzHhZmhIFiVHXFuS
---
## Learning outcomes

After completing this lesson, you will be able to:

- Apply GPT-2 to a large-scale text corpus in order to produce automatically-written responses to prompts based on the contents of the corpora
- Gain insight into common machine learning terminology and concepts which can be applied to other branches of machine learning
- Understand the ethical complications of producing this form of research

<ExternalResource title="Interested in learning more?" subtitle="Check out this lesson on Programming Historian's website" url="https://doi.org/10.46430/phen0104" />